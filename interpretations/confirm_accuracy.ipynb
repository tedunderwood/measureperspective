{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirming accuracy\n",
    "\n",
    "This notebook is a dead-simple way to check on accuracy figures reported in the article, assuming that you're willing to take the results of the modeling run itself on faith.\n",
    "\n",
    "If you want to reproduce the modeling ruin, you'll need to run **../logistic/main_experiment.py,** using the appropriate command for a given set of genre tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(probs, groundtruth):\n",
    "    ''' We assume these two vectors are paired.\n",
    "    '''\n",
    "    fn = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    for (p, g) in zip(probs, groundtruth):\n",
    "        if p >= 0.5 and g >= 0.5:\n",
    "            tp += 1\n",
    "        elif p >= 0.5 and g < 0.5:\n",
    "            fp += 1\n",
    "        elif p < 0.5 and g >= 0.5:\n",
    "            fn += 1\n",
    "        elif p < 0.5 and g < 0.5:\n",
    "            tn += 1\n",
    "        else:\n",
    "            print('hmmm ...')\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def check_file(filename):\n",
    "    path = '../modeloutput/' + filename + '.csv'\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    probs = df['probability']\n",
    "    groundtruth = df['realclass']\n",
    "    return accuracy(probs, groundtruth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8698630136986302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_file('maxaccuracy_mudies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
